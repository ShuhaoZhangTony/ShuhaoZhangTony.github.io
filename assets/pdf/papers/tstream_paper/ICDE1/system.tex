\section{\system overview}
\label{sec:arch}
%\system is a novel in-memory data stream processing system with built-in stateful management (incl. query and storage) capability.
%We implement a main memory DSP system for our experiments, name as \system supporting all five aforementioned shared state management algorithms.
%We implement all five aforementioned shared state management algorithms into a main memory DSP system for our experiments, named as \system.
In this section, we first introduce \system's APIs that can express stateful stream processing, and then demonstrate the supported consistency model in \system.
%Then, we gives an architectural overview of \system.

\subsection{APIs}
\system has an API simi  to existing DSPSs, e.g., Storm and Flink, where the application is expressed as a directed acyclic graph (DAG) with vertexes represent streaming operators and edges represent data flow among operators.
%\system has an API similar to existing DSPSs, e.g., Storm and Flink, where the application is expressed as a directed acyclic graph (DAG) with vertexes represent streaming operators and edges represent data flow among operators.
%Similar to existing DSPSs, \system requires the users 
%to declare the logic of streaming application 
%using a directed acyclic graph (DAG) with vertexes represent streaming operators and edges represent data flow among operators.
% be registered and stored in the system, and the {streaming application} is organized into a directed acyclic graph (DAG) of operators to execute.
%A \emph{data stream} consists of an infinite number of ordered events. 
%Each event (denoted as lower-case letters, e.g., $e$) has an associated timestamp, which can be either embedded in the event that indicates its real occurrence or assigned by the system when it arrives~\footnote{The former case requires the system to also handle out-of-arrival problem.}.
%The event instance arrived at the system is called ``external event'', and it determines the timestamp of all its descendant events that are generated as a result of operator execution.
%We also assign the generated output events the same \emph{timestamp} of the triggering event. 
%At a consequence, all subsequent processing triggered by one external (i.e., feed into the system) event appears to execute atomically.
%\textbf{Extended APIs of Shared State Management.}
%Operations triggered by a single input event is defined as one transaction processed by the system with ACID guarantees.
%Each newly incoming event causes a new process cycle (i.e., fetch-process-emit cycle as discussed in Section~\ref{sec:background}) of an operator. 
%Under such API, streaming operators in the application are not allowed to request any state management operations. 
We denote streaming operator without requesting any state management operations as $C$ (i.e., \emph{Compute-only}), which is the basic operator type supported in existing DSPSs.
In addition to that, 
%operators in the DAG may request state management operations, where operations triggered by a single input event are grouped into the same transaction.
\system enables the following three basic types of operators supporting state management operations, with which the users can compose most of the stateful stream processing application.
\begin{enumerate}
	\item \textbf{Read-only} ($R$) issues a read operation to the internal state and expect a return value from the state as input to further computation in the application.
	\item \textbf{Write-only} ($W$) issues a write operation to the internal state. It overwrites the value of the existing record with values provided by the application.
	\item \textbf{Read-Write} ($RW$) allows the application to read the value of the record, (optionally) modify the value, and write back to the internal state.
\end{enumerate}
% <<<<<<< HEAD
% Some streaming operators in the application may not necessarily issue any state management operations. We denote this type of operators as $C$ (i.e., \emph{compute-only}). 
% =======
%<<<<<<< HEAD
%Some streaming operators in the application may not necessarily issue any state management operations. We denote this type of operators as $C$ (i.e., \emph{Compute-only}). 
%=======
%>>>>>>> b80b24ea246a1ce5f737a531185c1318ba2835fe
% >>>>>>> a5c4ca73847adaa342879ec72a06e28902e05795

%Rely on these basic operators, \system provides a clear way to express and execute stateful stream processing application.
%Read or write to multiple records triggered by the same input event are composed into a single operation.

\subsection{Execution Model}
\system ensures the consistency of the streaming application's internal states. 
%without compromising performance.
%State management operations share many similarity to traditional transaction. 
%We henceforth use a transaction to denote one state management operation.
%\textbf{Define state.}
Similar to a database system, \system organizes internal states in relational tables. It also 
allows conventional database techniques, such as table partition, indexing, and compression. 
In this paper, we assume a row-oriented table with hash table constructed for indexing primary keys.  
%\textbf{State management operations.}
% \system performs State management operations are triggered by stream computation logic in run time.
As discussed in Section~\ref{sec:challenge}, the computations (or transactions in our context) triggered by different events must be executed with ACID guarantees.
% each state management operation (as transactions) need to be executed with ACID guarantees.
Specifically, the operations embraced in a single transaction
% all tasks in one operation (e.g., one operation may contain update requests to multiple records) 
shall be processed at once (atomicity); the state changes shall not violate any state constraint (consistency); multiple conflicting transactions shall run independently without interfering each other (isolation); and the changes made to the state shall be made persistent (durability). 

Beyond ACID properties, \system must also guarantee \emph{order-preserving consistency}
for the streaming application. 
This requires the users to assign a timestamp to every incoming streaming event so as to determine the execution order.
Different from existing DSPSs, \system
can extract more concurrency out of the streaming computation, even if out-of-core state is involved.
To achieve this objective, \system allows users to 
 % provides a flexible way to specify \emph{ordering-preserving consistency} in the application.
% Specifically, users can 
organize the streaming operators within the DAG into \emph{stages}, 
% <<<<<<< HEAD
within which the operators can access the same portion of the internal state\footnote{A DSPS can also adopt existing static analysis~\cite{Shasha:1995:TCA:211414.211427} method
to identify stages. We leave the static analysis-based solution as a future work.}.
 % computation triggered by a single event has to be executed sequentially.
%Correspondingly, we say that the transaction triggered by a single event is decomposed into multiple \emph{transaction slices}, 
%where each one slice is mapped to one stage. 
% Transaction slices triggered by a single event has to be executed sequentially due to their input-output dependency. 
% As a consequence, 
%More specifically, 
Due to the potentially conflicting state accesses, 
the transaction slices mapped to the same stage but triggered by different events shall be executed in the order
that is indicated by the incoming events' timestamps.
% can be executed in a concurrent manner, 
% and 
\system guarantees this ordering while attempting to maximizing the performance via order-preserving concurrent state accesses.
% =======
% within which the computation triggered by a single event has to be executed sequentially.
% %Correspondingly, we say that the transaction triggered by a single event is decomposed into multiple \emph{transaction slices}, 
% %where each one slice is mapped to one stage. 
% \tony{We adopt transaction chopping technique~\cite{Shasha:1995:TCA:211414.211427} for decomposing the transaction triggered by a single event into multiple \emph{transaction slices}, where each one slice is mapped to one stage. Transaction slices of the same transaction are executed sequentially for guaranteeing correctness.
% %. This approach considers //basic idea of the approach.
% }
% % Transaction slices triggered by a single event has to be executed sequentially due to their input-output dependency. 
% % As a consequence, 
% %More specifically, 
% Conversely, the transaction slices mapped to the same stage but triggered by different events can be executed in a concurrent manner, 
% and \system guarantees that, at any point of time, these concurrently executed transaction slices are ordered in the sequence that
% is indicated by the incoming events' timestamps.
% >>>>>>> b80b24ea246a1ce5f737a531185c1318ba2835fe
%\tony{The following description looks very restrictive, and ad-hoc.. we need to think about better ways to describe...}
%The organizing of stages are defined according to the application semantics, and it has the following rules.
%\begin{itemize}
%\item First, replicas of the same operator must be grouped into the same stage. This ensures that varying the parallelism of the operator does not change the original execution semantics. 
%\item Second, operators forming an ancestor-descendant relationship shall not be grouped into the same stage. 
%This is natural as the descendant operators rely on the output of ancestors.
%\item Third, an operator shall be grouped into only one stage. 
%\end{itemize}
%
%There are also optimization opportunities, such as multiple R operators need not be grouped in to the same stage as their execution order does not alter the shared state.
%
%<<<<<<< HEAD
%An example application is depicted in Figure~\ref{fig:overview_process}. 
%There are two points to take note. 
%First, operator $R_1$ is carried by two physical threads (i.e., $R_1$ and $R_1'$) concurrently processing computation triggered by different events to improve the system throughput, and they are grouped in the same stage. This ensures that varying the parallelism of the operator does not change the original execution semantics. 
%=======
% An example application is depicted in 

%<<<<<<< HEAD
%Figure~\ref{fig:overview_process} illustrates the concept of stage.
We now use an example stateful application containing five operators to illustrates the concept of stage.  
Figure~\ref{fig:overview_process}(a) shows the DAG of the streaming application. $C$ acts as a dispatcher partitioning input events to downstream operators. $R_1$ and $R_2$ are two operators containing read operations and $W_1$ and $W_2$ are operators that contains write operations.
In this application, $R_1$, $W_1$ and $W_2$, $R_2$ are respectively grouped into the same stage, meaning that the corresponding operators may access the same portion of the internal state.
%$R_1$, $R_1'$, $R_2$, $W_1$ and $W_2$ are carried by five physical threads running concurrently to improve system throughput. 
Figure~\ref{fig:overview_process}(b) shows one possible execution plan consuming three different incoming events. 
$R_1'$ and $R_1''$ are two physical threads spawned for $R_1$. $C'$, $W_1'$, $W_2'$ and $R_2'$ each represents a thread of the corresponding operator.
%=======
%Figure~\ref{fig:overview_process} illustrates the concept of stage using a stateful application supporting consuming three different incoming events. 
%%$R_1$, $R_1'$, $R_2$, $W_1$ and $W_2$ are carried by five physical threads running concurrently to improve system throughput. 
%$R_1$ and $R_1'$ are two physical threads spawned for a same operator with read operation, $R_2$ represent a thread of another operator with read operation, $W_1$ and $W_2$ each represents a thread of an operator with write operation.
%>>>>>>> d1954a94b825659620143af19d8b97f55ab0ba6d
There are three points to take note. 
First,  
%concurrently process computation triggered by different input events to improve system throughput. 
%The states read by $R_1$ and $R_1'$ are forwarded to C for further computation.
%First, 
$R_1'$ and $R_1''$ must be grouped into the same stage so that the system ensures that they are executed \emph{as if} there is a single thread of $R_1$ sequentially process its input events. This ensures that varying the parallelism of the operator will not change the original execution semantics. 
Second, outputs from $R_1'$ and $R_1''$ are forwarded to $W_2'$. Similarly, $W_1'$'s output is forwarded to $R_2'$. Each output event is assigned with timestamp same as the corresponding triggering input event. In this way, transaction slides triggered by the same input event is sequentially processed at different stages to guarantee correct streaming application semantics.
Third, there are two stages defined in this example, $R_1'$, $R_1''$ and $W_1'$ belong to the first; $W_2'$ and $R_2'$ belong to the second.
For transaction slices from the same stage, \system needs to make sure they are executed (although concurrently) preserving their triggering event sequence.
We illustrate how \system achieves this in the following discussion.

% There are two points to take note. 
%\yingjun{FIX!!}
%First, 
%operator $R_1$ is carried by two physical threads (i.e., $R_1$ and $R_1'$) concurrently processing computation triggered by different events to improve system throughput, and they are grouped in the same stage. This ensures that varying the parallelism of the operator does not change the original execution semantics. 
%%>>>>>>> d9cb57b2c0048d1d9bd383c573b3ea19a8ed8f01
%Second, 
%operator $W_1$ is grouped into the same stage of $R_1$ and $R_1'$. 
%This requires \system to make sure their read and write to the application internal state are preserving their triggering event sequence.

\begin{figure}
\centering
    \includegraphics*[width=0.4\textwidth]{overview_process.pdf}
    \caption{Example stateful application with two stages.}
    \label{fig:overview_process}
\end{figure}