\section{Conclusion}
\label{sec:conclu}
%As the scale and complexity of applications increase, it becomes more and more difficult to ensure the correct execution, while maintain high throughput low latency stream processing requirement, in the presence of concurrent accessing (read and write) over shared data sources. 
This paper proposes \system with a new design for supporting stateful stream processing. 
In order to take advantage of multi-core architectures, T-Stream detaches the state management from the streaming computation logic, and performs its internal state maintenance in a transactional manner. By eliminating the expensive synchronization primitives, T-Stream aggressively extracts parallelism opportunities by revealing the operation dependencies at runtime and guarantees the order for the access operations according to the timestamps attached to the incoming events.
We evaluate \system in detail on a modern 40-core machine.
%implement four alternative approaches inside the same system and evaluate all schemes in detail in a modern 40-core machine. 
Our results show that \system achieves a 2x higher throughput on average over existing solutions with similar or even smaller end-to-end processing latency.
%performs significantly better than others in most cases, and especially under highly contented workloads.
%\tony{
%\system's design can potentially cause higher end-to-end stream processing 
%latency due to its batching strategy. 
%However, 
%Our experimental results show that i
%Furthermore, its efficient use
%of multicores essentially reduces the time for processing event-triggered computation,
%hence leading to minimal latency overhead of the employed batching strategy.
%Furthermore, \system performs well even under contended workload thanks to work-stealing scheme, which is difficult, if not impossible, to be applied in existing lock-based schemes.
%The overhead pay for sorting and operation chain construction are overcome by performance gains from evaluation push-down and work-stealing scheme.
%}