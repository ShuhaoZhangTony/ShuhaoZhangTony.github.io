\paragraph{Multi-Query Optimization for Complex Event Processing in SAP ESP (ICDE'17)\\} 
As a PhD scholar in SAP Innovation Center Singapore from 2014 to 2018, I participated in improving SAP's stream processing platform, called SAP ESP.
The system aims at delivering real-time stream processing and analytics in time-critical applications. 
In SAP ESP, users can implement their complex event processing tasks, which continuously analysis real-time event streams and quickly identify pre-defined complex events.
%Being a sub-field of stream processing, 
%complex event processing (CEP) has been successfully applied in many areas such as Capital Markets,
%%~\cite{web}, 
%Internet of Things (IoT)
%%~\cite{fengjuan2013research} 
%and Data Center Intelligence.
%%~\cite{datacenter}. 
%Those domains are usually ``big data" applications with high velocity.
I have created MOTTO~\cite{motto,zhang2018multi}, a multi-query optimizer for complex event processing in SAP ESP as illustrated in Figure~\ref{figure:motto_optimizer}. 
MOTTO realizes more sharing opportunities by introducing pattern query decomposition and transformation. 
Those sharing techniques are also extented to support multiple nested pattern queries and pattern queries with different window constraints. 
Experiments demonstrate the efficiency of MOTTO with both real-world applications scenarios and sensitivity studies.

\begin{figure}[h]
\centering
\includegraphics[width=0.8\linewidth]{motto_optimizer}
\caption{Multi-query optimization workflow of MOTTO.}
\label{figure:motto_optimizer}
\end{figure}


\paragraph{Rvisiting the Design of Data Stream Processing Systems on Multi-Core Processors (ICDE'17)\\} 
For my Ph.D. dissertation, I was pioneering in discover the gaps between the design of modern stream processing systems and modern hardware architectures.
In particular, I summarize~\cite{profile} three common {design aspects} of modern DSPSs, including a) pipelined processing with message passing, b) on-demand data parallelism, and c) JVM-based implementation. 
Then, I conducted detailed profiling studies with micro benchmark on modern multi-socket multi-core by using Apache Strom and Flink as examples.
The results have shown that those designs have underutilized the scale-up architectures in these two key aspects:
a) The design of supporting both pipelined and data parallel processing {results} in a very complex massively parallel execution model in DSP systems, which causes high front-end stalls on a single CPU socket;
b) The design of continuous message passing mechanisms between operators severely limits the scalability of DSP systems on multi-socket multi-core architectures. 
For a concrete example, Figure~\ref{fig:I-trace} illustrates that the instruction footprint of both Storm and Flink exceed L1-Instruction cache, and hence leads frequent cache trashing.
Based on the profiling results, I have further proposed two optimizations~\cite{zhang2018efficient} and demonstrate promising performance improvements.


\begin{figure}
\centering
    \makebox[\textwidth][c]{
        \subfloat[Storm]{%
            \includegraphics*[width=0.4\textwidth]{storm-final.png}   %Replace by .pdf when submit
        }
        \subfloat[Flink]{%
            \includegraphics*[width=0.4\textwidth]{flink-final.png}  %Replace by .pdf when submit
        }
    }
    \caption{Instruction footprint between two consecutive invocations of the same function.}\label{fig:I-trace}

\end{figure}

\paragraph{\system: Scaling Data Stream Processing on Shared-Memory Multicore Architectures (SIGMOD'19)\\} 
My previous profiling study shows that existing DSPSs underutilized the underlying complex hardware microarchitecture and especially show poor scalability due to the unmanaged resource competition and unaware of NUMA effect. 
Hence, my subsequent effort spend on a complete revolution in designing next-generation stream
processing platform, namely BriskStream~\cite{briskstream}, specifically optimized for sharedmemory
multicore architectures.
To address NUMA effect, I have developed a new streaming execution plan optimization paradigm, namely Relative-Location Aware Scheduling (RLAS). 
%\system scales stream computation towards a hundred of cores under NUMA effect.
%The experiments on eight-sockets machines confirm that BriskStream significantly outperforms existing DSPSs up to an order of magnitude even without the tedious tuning process. 
Figure~\ref{figure:scale} shows the better scalability of
BriskStream than existing popular DSPSs on multi-socket servers by
taking Linear-Road Benchmark as an example. 
Unmanaged thread interference
and unnecessary remote memory access penalty prevent
existing DSPSs from scaling well on the modern multisockets machine.
The comprehensive experiments based on two eight-sockets machines confirm that \system significantly outperforms existing DSPSs up to an order of magnitude even without the tedious tuning process. 
In short, I showed how a DSPS, for the first time, scales stream computation towards a hundred of cores under NUMA effect.

\begin{figure}[h]
\centering
\includegraphics[width=0.5\linewidth]{scalability_lr}
\caption{System scalability comparison based on Linear-Road Benchmark.}
\label{figure:scale}
\end{figure}

%The discussion on the different aspects discussed above illustrate the challenges we may confront in building a high performance DSPSs that can effectively utilize modern multicore architectures.
%These aspects are tightly coupled with each other, and the redesign of a single component can directly affect the effectiveness of others. 
%Witnessing these problems, in this thesis, we study the problem of building scalable multicore DSPSs from a systematic perspective. 
%In particular, we discuss the design and implementation of two core components of DSPSs, including execution plan optimization and state management. 
%Throughout this thesis, we conduct comprehensive performance study and propose novel mechanisms to address the issues identified above. In addition, we also point out some future works in designing and implementing next-generation multicore DSPSs.

\paragraph{Towards Concurrent Stateful Stream Processing on Multicore Processors (To appear in ICDE'20)\\}
DSPS with transactional state management relieves users from managing state consistency by themselves,  
and has recently received attention from both academia and industry community. 
However, scaling stream processing while providing transactional state management 
on modern multicore processors is challenging. 
On the one hand, to achieve both low latency and high throughput, 
DSPSs can process multiple input events at the same time in order to aggressively exploit parallelism.
On the other hand, processing different events concurrently may lead to conflict accesses (reads and writes) to the same application state, hence leading to higher chances of violating transactional state consistency. 
To make things worse, more than simply guaranteeing the ACID properties preserved in the relational database systems, DSPSs further need to enforce the state access \emph{order} according to the input event {sequence}.
Witnessing those issues, I have developed \tsystem~\cite{tstream}, a new DSPS that can support highly scalable stream processing with transactional state consistency guarantee on multicores.
In order to take advantage of multicore architectures, \tsystem detaches the state management from the streaming computation logic, and performs its internal state maintenance asynchronously. 
By eliminating the expensive synchronization primitives, \tsystem aggressively extracts parallelism opportunities by revealing the operation dependencies at runtime.
%We evaluate \tsystem in detail on a modern 40-core machine.
The initial results show that \tsystem achieves several times higher throughput on average over existing solutions with similar or even smaller end-to-end processing latency.

