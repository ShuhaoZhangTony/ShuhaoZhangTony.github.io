@inproceedings{9101749,
	title        = {Towards Concurrent Stateful Stream Processing on Multicore Processors},
	author       = {Shuhao {Zhang} and Y. {Wu} and F. {Zhang} and B. {He}},
	year         = 2020,
	booktitle    = {2020 IEEE 36th International Conference on Data Engineering (ICDE)},
	volume       = {},
	number       = {},
	pages        = {1537--1548},
	doi          = {10.1109/ICDE48307.2020.00136},
	pdf          = {papers/tstream.pdf},
	abstract     = {Recent data stream processing systems (DSPSs) can achieve excellent performance when processing large volumes of data under tight latency constraints. However, they sacrifice support for concurrent state access that eases the burden of developing stateful stream applications. Recently, some have proposed managing concurrent state access during stream processing by modeling state accesses as transactions. However, these are realized with locks involving serious contention overhead. The coarse-grained processing paradigm adopted in these proposals magnify contention issues and does not exploit modern multicore architectures to their full potential. This paper introduces TStream, a novel DSPS supporting efficient concurrent state access on multicore processors. Transactional semantics is employed like previous work, but scalability is greatly improved due to two novel designs: 1) dual-mode scheduling, which exposes more parallelism opportunities, 2) dynamic restructuring execution, which aggressively exploits the parallelism opportunities from dual-mode scheduling without centralized lock contentions. To validate our proposal, we evaluate TStream with a benchmark of four applications on a modern multicore machine. Experimental results show that 1) TStream achieves up to 4.8 times higher throughput with similar processing latency compared to the state-of-the-art and 2) unlike prior solutions, TStream is highly tolerant of varying application workloads such as key skewness and multi-partition state accesses.},
	slides       = {talks/tstream_icde.pdf},
    code ={https://github.com/Xtra-Computing/briskstream/tree/TStream}
}
@article{OJIOT_2020v6i1n07_Zeuch,
	title        = {NebulaStream: Complex Analytics Beyond the Cloud},
	author       = {Steffen Zeuch and Eleni Tzirita Zacharatou and Shuhao Zhang and Xenofon Chatziliadis and Ankit Chaudhary and Bonaventura Del Monte and Dimitrios Giouroukis and Philipp M. Grulich and Ariane Ziehn and Volker Mark},
	year         = 2020,
	journal      = {Open Journal of Internet Of Things (OJIOT)},
	publisher    = {RonPub},
	volume       = 6,
	number       = 1,
	pages        = {66--81},
	issn         = {2364-7108},
	url          = {https://www.ronpub.com/ojiot/OJIOT_2020v6i1n07_Zeuch.html},
	bibsource    = {RonPub},
	abstract     = {The arising Internet of Things (IoT) will require significant changes to current stream processing engines (SPEs) to enable large-scale IoT applications. In this paper, we present challenges and opportunities for an IoT data management system to enable complex analytics beyond the cloud. As one of the most important upcoming IoT applications, we focus on the vision of a smart city. The goal of this paper is to bridge the gap between the requirements of upcoming IoT applications and the supported features of an IoT data management system. To this end, we outline how state-of-the-art SPEs have to change to exploit the new capabilities of the IoT and showcase how we tackle IoT challenges in our own system, NebulaStream. This paper lays the foundation for a new type of systems that leverages the IoT to enable large-scale applications over millions of IoT devices in highly dynamic and geo-distributed environments.}
}
@inproceedings{Zhang2020PewLSTM,
	title        = {PewLSTM: Periodic LSTM with Weather-Aware Gating Mechanism for Parking Behavior Prediction},
	author       = {Feng Zhang, Ningxuan Feng, Yani Liu, Cheng Yang, Jidong Zhai, Shuhao Zhang, Bingsheng He, Jiazao Lin, Xiaoyong Du},
	year         = 2020,
	booktitle   = {International Joint Conference on Artificial Intelligence(IJCAI)},
	abstract     = {In big cities, there are plenty of parking spaces, but we often find nowhere to park. For example, New York has 1.4 million cars and 4.4 million on-street parking spaces, but it is still not easy to find a parking place near our destination, especially during peak hours. The reason is the lack of prediction of parking behavior. If we could provide parking behavior in advance, we can ease this parking problem that affects human well-being. We observe that parking lots have periodic parking patterns, which is an important factor for parking behavior prediction. Unfortunately, existing work ignores such periodic parking patterns in parking behavior prediction, and thus incurs low accuracy. To solve this problem, we propose PewLSTM, a novel periodic weather-aware LSTM model that successfully predicts the parking behavior based on historical records, weather, environments, and weekdays. PewLSTM has been successfully integrated into a real parking space reservation system, ThsParking, which is one of the top smart parking platforms in China. Based on 452,480real parking records in 683 days from 10 parking lots, PewLSTM yields 85.3% parking prediction accuracy, which is about 20% higher than the state-of-the-art parking behavior prediction method. The code and data can be obtained fromhttps://github.com/NingxuanFeng/PewLSTM.}
}
@inproceedings{254469,
	title        = {FineStream: Fine-Grained Window-Based Stream Processing on CPU-GPU Integrated Architectures},
	author       = {Feng Zhang and Lin Yang and Shuhao Zhang and Bingsheng He and Wei Lu and Xiaoyong Du},
	year         = 2020,
	month        = jul,
	booktitle    = {2020 {USENIX} Annual Technical Conference ({USENIX} {ATC} 20)},
	publisher    = {{USENIX} Association},
	pages        = {633--647},
	isbn         = {978-1-939133-14-4},
	url          = {https://www.usenix.org/conference/atc20/presentation/zhang-feng},
	abstract     = {Accelerating SQL queries on stream processing by utilizing heterogeneous coprocessors, such as GPUs, has shown to be an effective approach. Most works show that heterogeneous processors bring significant performance improvement because of their high parallelism and computation capacity. However, the discrete memory architectures with relatively low PCI-e bandwidth and high latency have dragged down the benefits of heterogeneous coprocessors. Recently, hardware vendors propose CPU-GPU integrated architectures that integrate CPU and GPU on the same chip. This integration provides new opportunities for fine-grained cooperation be-tween CPU and GPU for optimizing SQL queries on stream processing. In this paper, we propose a data stream system, called FineStream, for efficient window-based stream pro-cessing on integrated architectures. Particularly, FineStreamperforms fine-grained workload scheduling between CPU and GPU to take advantage of both architectures, and also targets at dynamic stream query co-processing with window handling. Our experimental results show that 1) on integrated architectures, FineStream achieves an average 52% throughput improvement and 36% lower latency over the state-of-the-art stream processing engine; 2) compared to the stream processing engine on the discrete architecture, FineStream on the integrated architecture achieves 10.4x price-throughput ratio, 1.8x energy efficiency, and can enjoy lower latency benefits.}
}
@article{10.1145/3385658.3385662,
	title        = {Hardware-Conscious Stream Processing: A Survey},
	author       = {Zhang, Shuhao and Zhang, Feng and Wu, Yingjun and He, Bingsheng and Johns, Paul},
	year         = 2020,
	month        = feb,
	journal      = {SIGMOD Rec.},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	volume       = 48,
	number       = 4,
	pages        = {18–29},
	doi          = {10.1145/3385658.3385662},
	issn         = {0163-5808},
	url          = {https://doi.org/10.1145/3385658.3385662},
	issue_date   = {December 2019},
	abstract     = {Data stream processing systems (DSPSs) enable users to express and run stream applications to continuously process data streams. To achieve realtime data analytics, recent researches keep focusing on optimizing the system latency and throughput. Witnessing the recent great achievements in the computer architecture community, researchers and practitioners have investigated the potential of adoption hardware-conscious stream processing by better utilizing modern hardware capacity in DSPSs. In this paper, we conduct a systematic survey of recent work in the field, particularly along with the following three directions: 1) computation optimization, 2) stream I/O optimization, and 3) query deployment. Finally, we advise on potential future research directions.},
	numpages     = 12
}
@inproceedings{8919445,
	title        = {TraV: An Interactive Exploration System for Massive Trajectory Data},
	author       = {J. {Ang} and T. {Fu} and J. {Paul} and Shuhao {Zhang} and B. {He} and T. S. D. {Wenceslao} and S. Y. {Tan}},
	year         = 2019,
	booktitle    = {2019 IEEE Fifth International Conference on Multimedia Big Data (BigMM)},
	volume       = {},
	number       = {},
	pages        = {309--313},
	doi          = {10.1109/BigMM.2019.000-4}
}
@inproceedings{10.1145/3299869.3300067,
	title        = {BriskStream: Scaling Data Stream Processing on Shared-Memory Multicore Architectures},
	author       = {Zhang, Shuhao and He, Jiong and Zhou, Amelie Chi and He, Bingsheng},
	year         = 2019,
	booktitle    = {Proceedings of the 2019 International Conference on Management of Data},
	location     = {Amsterdam, Netherlands},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {SIGMOD '19},
	pages        = {705–722},
	doi          = {10.1145/3299869.3300067},
	isbn         = 9781450356435,
	url          = {https://doi.org/10.1145/3299869.3300067},
	abstract     = {We introduce BriskStream, an in-memory data stream processing system (DSPSs) specifically designed for modern shared-memory multicore architectures. BriskStream's key contribution is an execution plan optimization paradigm, namely RLAS, which takes relative-location (i.e., NUMA distance) of each pair of producer-consumer operators into consideration. We propose a branch and bound based approach with three heuristics to resolve the resulting nontrivial optimization problem. The experimental evaluations demonstrate that BriskStream yields much higher throughput and better scalability than existing DSPSs on multi-core architectures when processing different types of workloads.},
	numpages     = 18,
	keywords     = {numa-awareness, operator replication and placement},
    pdf          = {papers/briskstream.pdf},
    code         = {https://github.com/Xtra-Computing/briskstream}
}
@inproceedings{7930061,
	title        = {Multi-Query Optimization for Complex Event Processing in SAP ESP},
	author       = {Shuhao {Zhang} and H. T. {Vo} and D. {Dahlmeier} and B. {He}},
	year         = 2017,
	booktitle    = {2017 IEEE 33rd International Conference on Data Engineering (ICDE)},
	volume       = {},
	number       = {},
	pages        = {1213--1224},
	doi          = {10.1109/ICDE.2017.166},
    pdf          = {papers/MOTTO.pdf},
}
@inproceedings{7930015,
	title        = {Revisiting the Design of Data Stream Processing Systems on Multi-Core Processors},
	author       = {Shuhao {Zhang} and B. {He} and D. {Dahlmeier} and A. C. {Zhou} and T. {Heinze}},
	year         = 2017,
	booktitle    = {2017 IEEE 33rd International Conference on Data Engineering (ICDE)},
	volume       = {},
	number       = {},
	pages        = {659--670},
	doi          = {10.1109/ICDE.2017.119},
    pdf          = {papers/profile.pdf},
}
@inproceedings{7877153,
	title        = {Elastic Multi-resource Fairness: Balancing Fairness and Efficiency in Coupled CPU-GPU Architectures},
	author       = {S. {Tang} and B. {He} and Shuhao {Zhang} and Z. {Niu}},
	year         = 2016,
	booktitle    = {SC '16: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
	volume       = {},
	number       = {},
	pages        = {875--886},
	doi          = {10.1109/SC.2016.74}
}
@article{7501903,
	title        = {Understanding Co-Running Behaviors on Integrated CPU/GPU Architectures},
	author       = {F. {Zhang} and J. {Zhai} and B. {He} and Shuhao {Zhang} and W. {Chen}},
	year         = 2017,
	journal      = {IEEE Transactions on Parallel and Distributed Systems},
	volume       = 28,
	number       = 3,
	pages        = {905--918},
	doi          = {10.1109/TPDS.2016.2586074}
}
@article{7425227,
	title        = {Melia: A MapReduce Framework on OpenCL-Based FPGAs},
	author       = {Z. {Wang} and Shuhao {Zhang} and B. {He} and W. {Zhang}},
	year         = 2016,
	journal      = {IEEE Transactions on Parallel and Distributed Systems},
	volume       = 27,
	number       = 12,
	pages        = {3547--3560},
	doi          = {10.1109/TPDS.2016.2537805}
}
@inproceedings{7330177,
	title        = {To Co-run, or Not to Co-run: A Performance Study on Integrated Architectures},
	author       = {F. {Zhang} and J. {Zhai} and W. {Chen} and B. {He} and Shuhao {Zhang}},
	year         = 2015,
	booktitle    = {2015 IEEE 23rd International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems},
	volume       = {},
	number       = {},
	pages        = {89--92},
	doi          = {10.1109/MASCOTS.2015.27}
}
@article{10.14778/2735496.2735497,
	title        = {In-Cache Query Co-Processing on Coupled CPU-GPU Architectures},
	author       = {He, Jiong and Zhang, Shuhao and He, Bingsheng},
	year         = 2014,
	month        = dec,
	journal      = {Proc. VLDB Endow.},
	publisher    = {VLDB Endowment},
	volume       = 8,
	number       = 4,
	pages        = {329–340},
	doi          = {10.14778/2735496.2735497},
	issn         = {2150-8097},
	url          = {https://doi.org/10.14778/2735496.2735497},
	issue_date   = {December 2014},
	abstract     = {Recently, there have been some emerging processor designs that the CPU and the GPU (Graphics Processing Unit) are integrated in a single chip and share Last Level Cache (LLC). However, the main memory bandwidth of such coupled CPU-GPU architectures can be much lower than that of a discrete GPU. As a result, current GPU query co-processing paradigms can severely suffer from memory stalls. In this paper, we propose a novel in-cache query co-processing paradigm for main memory On-Line Analytical Processing (OLAP) databases on coupled CPU-GPU architectures. Specifically, we adapt CPU-assisted prefetching to minimize cache misses in GPU query co-processing and CPU-assisted decompression to improve query execution performance. Furthermore, we develop a cost model guided adaptation mechanism for distributing the workload of prefetching, decompression, and query execution between CPU and GPU. We implement a system prototype and evaluate it on two recent AMD APUs A8 and A10. The experimental results show that 1) in-cache query co-processing can effectively improve the performance of the state-of-the-art GPU co-processing paradigm by up to 30% and 33% on A8 and A10, respectively, and 2) our workload distribution adaption mechanism can significantly improve the query performance by up to 36% and 40% on A8 and A10, respectively.},
	numpages     = 12
}
@article{10.14778/2536274.2536319,
	title        = {OmniDB: Towards Portable and Efficient Query Processing on Parallel CPU/GPU Architectures},
	author       = {Zhang, Shuhao and He, Jiong and He, Bingsheng and Lu, Mian},
	year         = 2013,
	month        = aug,
	journal      = {Proc. VLDB Endow.},
	publisher    = {VLDB Endowment},
	volume       = 6,
	number       = 12,
	pages        = {1374–1377},
	doi          = {10.14778/2536274.2536319},
	issn         = {2150-8097},
	url          = {https://doi.org/10.14778/2536274.2536319},
	issue_date   = {August 2013},
	abstract     = {Driven by the rapid hardware development of parallel CPU/GPU architectures, we have witnessed emerging relational query processing techniques and implementations on those parallel architectures. However, most of those implementations are not portable across different architectures, because they are usually developed from scratch and target at a specific architecture. This paper proposes a kernel-adapter based design (OmniDB), a portable yet efficient query processor on parallel CPU/GPU architectures. OmniDB attempts to develop an extensible query processing kernel (qKernel) based on an abstract model for parallel architectures, and to leverage an architecture-specific layer (adapter) to make qKernel be aware of the target architecture. The goal of OmniDB is to maximize the common functionality in qKernel so that the development and maintenance efforts for adapters are minimized across different architectures. In this demo, we demonstrate our initial efforts in implementing OmniDB, and present the preliminary results on the portability and efficiency.},
	numpages     = 4
}
